{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Metadata Utilities\n",
        "\n",
        "The `metadata.py` module in `flowerpower-io` provides utility functions for extracting and managing metadata from various data structures. This metadata includes schema information, data dimensions, file paths, and timestamps, which are crucial for understanding data characteristics and lineage.\n",
        "\n",
        "## Functions\n",
        "\n",
        "### `get_serializable_schema`\n",
        "\n",
        "::: {.callout-note}\n",
        "## `get_serializable_schema`\n",
        "Converts the schema (data types) of a given DataFrame or data structure into a serializable dictionary format. This is useful for storing schema information in a persistent, human-readable way.\n",
        ":::\n",
        "\n",
        "**Definition**:\n",
        "```python\n",
        "def get_serializable_schema(\n",
        "    data: (\n",
        "        pd.DataFrame\n",
        "        | pl.DataFrame\n",
        "        | pl.LazyFrame\n",
        "        | duckdb.DuckDBPyRelation\n",
        "        | pa.Table\n",
        "        | pa.Schema\n",
        "        | pa.RecordBatch\n",
        "        | pa.RecordBatchReader\n",
        "        | pds.Dataset\n",
        "    ),\n",
        ") -> dict[str, str]:\n",
        "```\n",
        "\n",
        "**Arguments**:\n",
        "\n",
        "*   `data`: The input data structure (Pandas DataFrame, Polars DataFrame, PyArrow Table, DuckDB Relation, etc.) from which to extract the schema.\n",
        "\n",
        "**Returns**:\n",
        "\n",
        "*   `dict[str, str]`: A dictionary where keys are column names and values are their corresponding data types as strings.\n",
        "\n",
        "**Example**:"
      ],
      "id": "8ce6985f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: true\n",
        "\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "import pyarrow as pa\n",
        "from flowerpower_io.metadata import get_serializable_schema\n",
        "\n",
        "# Example with Pandas DataFrame\n",
        "df_pandas = pd.DataFrame({'col1': [1, 2], 'col2': ['A', 'B']})\n",
        "pandas_schema = get_serializable_schema(df_pandas)\n",
        "print(\"Pandas Schema:\", pandas_schema)\n",
        "\n",
        "# Example with Polars DataFrame\n",
        "df_polars = pl.DataFrame({'col3': [True, False], 'col4': [1.1, 2.2]})\n",
        "polars_schema = get_serializable_schema(df_polars)\n",
        "print(\"Polars Schema:\", polars_schema)\n",
        "\n",
        "# Example with PyArrow Table\n",
        "table_arrow = pa.table({'col5': [10, 20], 'col6': ['X', 'Y']})\n",
        "pyarrow_schema = get_serializable_schema(table_arrow)\n",
        "print(\"PyArrow Schema:\", pyarrow_schema)"
      ],
      "id": "dc315907",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `get_dataframe_metadata`\n",
        "\n",
        "::: {.callout-note}\n",
        "## `get_dataframe_metadata`\n",
        "Generates a comprehensive metadata dictionary for a DataFrame, including information such as path, format, timestamp, schema, number of columns, rows, and files.\n",
        ":::\n",
        "\n",
        "**Definition**:\n",
        "```python\n",
        "def get_dataframe_metadata(\n",
        "    df: pd.DataFrame\n",
        "    | pl.DataFrame\n",
        "    | pl.LazyFrame\n",
        "    | pa.Table\n",
        "    | pa.RecordBatch\n",
        "    | pa.RecordBatchReader\n",
        "    | list[\n",
        "        pd.DataFrame\n",
        "        | pl.DataFrame\n",
        "        | pl.LazyFrame\n",
        "        | pa.Table\n",
        "        | pa.RecordBatch\n",
        "        | pa.RecordBatchReader\n",
        "    ],\n",
        "    path: str | list[str] | None = None,\n",
        "    format: str | None = None,\n",
        "    topic: str | None = None,\n",
        "    num_files: int | None = None,\n",
        "    partition_columns: list[str] | None = None,\n",
        "    fs: AbstractFileSystem | None = None,\n",
        "    **kwargs,\n",
        ") -> dict:\n",
        "```\n",
        "\n",
        "**Arguments**:\n",
        "\n",
        "*   `df`: The input DataFrame or list of DataFrames.\n",
        "*   `path` (`str | list[str] | None`, optional): Path to the file(s) from which the DataFrame was loaded.\n",
        "*   `format` (`str | None`, optional): Format of the data (e.g., `\"csv\"`, `\"parquet\"`).\n",
        "*   `topic` (`str | None`, optional): Topic name for stream-based data (e.g., MQTT).\n",
        "*   `num_files` (`int | None`, optional): Number of files if data is from multiple files.\n",
        "*   `partition_columns` (`list[str] | None`, optional): List of columns used for partitioning.\n",
        "*   `fs` (`AbstractFileSystem | None`, optional): Filesystem instance.\n",
        "*   `**kwargs`: Additional key-value pairs to include in the metadata.\n",
        "\n",
        "**Returns**:\n",
        "\n",
        "*   `dict`: A dictionary containing the extracted metadata.\n",
        "\n",
        "**Example**:"
      ],
      "id": "0559fb1e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: true\n",
        "\n",
        "import pandas as pd\n",
        "from flowerpower_io.metadata import get_dataframe_metadata\n",
        "import datetime as dt\n",
        "\n",
        "df_sample = pd.DataFrame({'colA': [1, 2], 'colB': ['X', 'Y']})\n",
        "metadata = get_dataframe_metadata(\n",
        "    df_sample,\n",
        "    path=\"/data/sample.csv\",\n",
        "    format=\"csv\",\n",
        "    custom_field=\"value\"\n",
        ")\n",
        "print(\"DataFrame Metadata:\", metadata)"
      ],
      "id": "e2d14cf9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `get_duckdb_metadata`\n",
        "\n",
        "::: {.callout-note}\n",
        "## `get_duckdb_metadata`\n",
        "Retrieves metadata specifically for DuckDB relations, including schema, shape, and file information if applicable.\n",
        ":::\n",
        "\n",
        "**Definition**:\n",
        "```python\n",
        "def get_duckdb_metadata(\n",
        "    rel: duckdb.DuckDBPyRelation,\n",
        "    path: str,\n",
        "    format: str,\n",
        "    fs: AbstractFileSystem | None = None,\n",
        "    include_shape: bool = False,\n",
        "    include_num_files: bool = False,\n",
        "    partition_columns: list[str] | None = None,\n",
        "    **kwargs,\n",
        ") -> dict:\n",
        "```\n",
        "\n",
        "**Arguments**:\n",
        "\n",
        "*   `rel`: The DuckDBPyRelation object.\n",
        "*   `path` (`str`): Path to the file(s) that the DuckDBPyRelation was loaded from.\n",
        "*   `format` (`str`): Format of the data.\n",
        "*   `fs` (`AbstractFileSystem | None`, optional): Filesystem instance.\n",
        "*   `include_shape` (`bool`, optional): Whether to include the shape (rows, columns) in the metadata. Defaults to `False`.\n",
        "*   `include_num_files` (`bool`, optional): Whether to include the number of files in the metadata. Defaults to `False`.\n",
        "*   `partition_columns` (`list[str] | None`, optional): List of columns used for partitioning.\n",
        "*   `**kwargs`: Additional key-value pairs to include in the metadata.\n",
        "\n",
        "**Returns**:\n",
        "\n",
        "*   `dict`: A dictionary containing the extracted DuckDB metadata.\n",
        "\n",
        "**Example**:"
      ],
      "id": "11f050b0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: true\n",
        "\n",
        "import duckdb\n",
        "from flowerpower_io.metadata import get_duckdb_metadata\n",
        "\n",
        "conn = duckdb.connect(database=\":memory:\")\n",
        "rel = conn.from_dict({'a': [1, 2], 'b': ['x', 'y']})\n",
        "duckdb_meta = get_duckdb_metadata(\n",
        "    rel,\n",
        "    path=\"memory_db\",\n",
        "    format=\"duckdb\",\n",
        "    include_shape=True\n",
        ")\n",
        "print(\"DuckDB Metadata:\", duckdb_meta)\n",
        "conn.close()"
      ],
      "id": "b2e19fea",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `get_pyarrow_dataset_metadata`\n",
        "\n",
        "::: {.callout-note}\n",
        "## `get_pyarrow_dataset_metadata`\n",
        "Extracts metadata from a PyArrow Dataset, including schema, file paths, and partitioning information.\n",
        ":::\n",
        "\n",
        "**Definition**:\n",
        "```python\n",
        "def get_pyarrow_dataset_metadata(\n",
        "    ds: pds.Dataset,\n",
        "    path: str,\n",
        "    format: str,\n",
        "    **kwargs,\n",
        ") -> dict:\n",
        "```\n",
        "\n",
        "**Arguments**:\n",
        "\n",
        "*   `ds`: The PyArrow Dataset object.\n",
        "*   `path` (`str`): Path to the dataset.\n",
        "*   `format` (`str`): Format of the dataset.\n",
        "*   `**kwargs`: Additional key-value pairs to include in the metadata.\n",
        "\n",
        "**Returns**:\n",
        "\n",
        "*   `dict`: A dictionary containing the extracted PyArrow Dataset metadata.\n",
        "\n",
        "**Example**:"
      ],
      "id": "f829eb11"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: true\n",
        "\n",
        "import pyarrow.dataset as pds\n",
        "import pyarrow as pa\n",
        "import os\n",
        "import shutil\n",
        "from flowerpower_io.metadata import get_pyarrow_dataset_metadata\n",
        "\n",
        "# Create a dummy dataset directory\n",
        "dataset_dir = \"temp_pyarrow_dataset\"\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "pa.csv.write_csv(pa.table({'a': [1, 2]}), os.path.join(dataset_dir, \"data.csv\"))\n",
        "\n",
        "# Create a PyArrow Dataset\n",
        "dataset = pds.dataset(dataset_dir, format=\"csv\")\n",
        "pyarrow_dataset_meta = get_pyarrow_dataset_metadata(\n",
        "    dataset,\n",
        "    path=dataset_dir,\n",
        "    format=\"csv\"\n",
        ")\n",
        "print(\"PyArrow Dataset Metadata:\", pyarrow_dataset_meta)\n",
        "\n",
        "# Clean up\n",
        "shutil.rmtree(dataset_dir)"
      ],
      "id": "6e553a3a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `get_delta_metadata`\n",
        "\n",
        "::: {.callout-note}\n",
        "## `get_delta_metadata`\n",
        "Extracts metadata specifically from a DeltaTable object, providing details like name, description, ID, schema, partition columns, and number of files.\n",
        ":::\n",
        "\n",
        "**Definition**:\n",
        "```python\n",
        "def get_delta_metadata(\n",
        "    dtable: DeltaTable,\n",
        "    path: str,\n",
        "    **kwargs,\n",
        ") -> dict:\n",
        "```\n",
        "\n",
        "**Arguments**:\n",
        "\n",
        "*   `dtable`: The DeltaTable object.\n",
        "*   `path` (`str`): Path to the Delta Lake table.\n",
        "*   `**kwargs`: Additional key-value pairs to include in the metadata.\n",
        "\n",
        "**Returns**:\n",
        "\n",
        "*   `dict`: A dictionary containing the extracted DeltaTable metadata.\n",
        "\n",
        "**Example**:"
      ],
      "id": "f1a0be5a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: true\n",
        "\n",
        "# This example requires a Delta Lake table to exist.\n",
        "# For demonstration, we'll show the function call.\n",
        "from deltalake import DeltaTable\n",
        "from flowerpower_io.metadata import get_delta_metadata\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Create a dummy Delta Lake table (requires deltalake package and rust toolchain)\n",
        "# from delta import DeltaTable, configure_spark_with_delta_pip\n",
        "# builder = configure_spark_with_delta_pip()\n",
        "# spark = builder.getOrCreate()\n",
        "# data = spark.range(0, 5).toDF(\"id\")\n",
        "# delta_path = \"temp_delta_table\"\n",
        "# data.write.format(\"delta\").save(delta_path)\n",
        "\n",
        "# Assuming a DeltaTable exists at 'path_to_delta_table'\n",
        "# delta_table = DeltaTable(\"path_to_delta_table\")\n",
        "# delta_meta = get_delta_metadata(delta_table, path=\"path_to_delta_table\")\n",
        "# print(\"DeltaTable Metadata:\", delta_meta)\n",
        "\n",
        "# Placeholder for demonstration without actual DeltaTable setup\n",
        "print(\"DeltaTable example skipped as it requires Delta Lake setup.\")"
      ],
      "id": "5aa6fa25",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `get_mqtt_metadata`\n",
        "\n",
        "::: {.callout-note}\n",
        "## `get_mqtt_metadata`\n",
        "Generates metadata for MQTT payloads, including topic, format, timestamp, schema, and basic data dimensions. This function requires the `orjson` library.\n",
        ":::\n",
        "\n",
        "**Definition**:\n",
        "```python\n",
        "def get_mqtt_metadata(\n",
        "    payload: bytes | dict[str, any],\n",
        "    topic: str | None = None,\n",
        "    **kwargs,\n",
        ") -> dict:\n",
        "```\n",
        "\n",
        "**Arguments**:\n",
        "\n",
        "*   `payload` (`bytes | dict[str, any]`): The MQTT message payload, either as bytes or a parsed dictionary.\n",
        "*   `topic` (`str | None`, optional): The MQTT topic from which the payload was received.\n",
        "*   `**kwargs`: Additional key-value pairs to include in the metadata.\n",
        "\n",
        "**Returns**:\n",
        "\n",
        "*   `dict`: A dictionary containing the extracted MQTT metadata.\n",
        "\n",
        "**Example**:"
      ],
      "id": "d2d3eea2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: true\n",
        "\n",
        "import orjson\n",
        "import datetime as dt\n",
        "from flowerpower_io.metadata import get_mqtt_metadata\n",
        "\n",
        "# Example with a dictionary payload\n",
        "mqtt_payload_dict = {\"sensor_id\": \"temp_01\", \"temperature\": 25.5, \"unit\": \"C\"}\n",
        "mqtt_meta_dict = get_mqtt_metadata(\n",
        "    mqtt_payload_dict,\n",
        "    topic=\"sensors/temperature\"\n",
        ")\n",
        "print(\"MQTT Metadata (Dict Payload):\", mqtt_meta_dict)\n",
        "\n",
        "# Example with a bytes payload\n",
        "mqtt_payload_bytes = orjson.dumps({\"event\": \"door_open\", \"timestamp\": dt.datetime.now().isoformat()})\n",
        "mqtt_meta_bytes = get_mqtt_metadata(\n",
        "    mqtt_payload_bytes,\n",
        "    topic=\"home/security\"\n",
        ")\n",
        "print(\"MQTT Metadata (Bytes Payload):\", mqtt_meta_bytes)"
      ],
      "id": "4f44b81d",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/z0043ddz/coding/libs/flowerpower-io/.venv/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}