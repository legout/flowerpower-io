{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Examples\n",
        "\n",
        "This section provides various examples demonstrating how to use `flowerpower-io` for common data loading, saving, and conversion tasks.\n",
        "\n",
        "## Setup for Examples\n",
        "\n",
        "To run these examples, you'll need `pandas`, `polars`, and `pyarrow` installed, in addition to `flowerpower-io`."
      ],
      "id": "5e198c5d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: true\n",
        "\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "import pyarrow as pa\n",
        "import tempfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Import FlowerPower IO classes\n",
        "from flowerpower_io.loader.csv import CSVFileReader\n",
        "from flowerpower_io.saver.parquet import ParquetFileWriter\n",
        "from flowerpower_io.loader.sqlite import SQLiteReader\n",
        "from flowerpower_io.saver.sqlite import SQLiteWriter\n",
        "\n",
        "# Create sample data\n",
        "sample_data = {\n",
        "    'id': range(1, 101),\n",
        "    'name': [f'Person_{i}' for i in range(1, 101)],\n",
        "    'age': [20 + (i % 50) for i in range(1, 101)],\n",
        "    'city': ['New York', 'London', 'Tokyo', 'Paris', 'Berlin'] * 20,\n",
        "    'salary': [50000 + (i * 1000) for i in range(1, 101)]\n",
        "}\n",
        "\n",
        "# Create a temporary directory for our demo files\n",
        "temp_dir = tempfile.mkdtemp()\n",
        "csv_path = os.path.join(temp_dir, 'sample_data.csv')\n",
        "parquet_path = os.path.join(temp_dir, 'sample_data.parquet')\n",
        "db_path = os.path.join(temp_dir, 'sample_data.db')\n",
        "\n",
        "# Create CSV file using pandas\n",
        "df_pandas_original = pd.DataFrame(sample_data)\n",
        "df_pandas_original.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Created sample CSV file at: {csv_path}\")\n",
        "print(f\"Sample data shape: {df_pandas_original.shape}\")"
      ],
      "id": "c7173272",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Reading CSV and Converting Formats\n",
        "\n",
        "This example demonstrates how to read a CSV file using `CSVFileReader` and convert the data into Pandas DataFrame, Polars DataFrame, and PyArrow Table formats."
      ],
      "id": "90e9f421"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: true\n",
        "\n",
        "# Reading CSV Files with CSVFileReader\n",
        "csv_reader = CSVFileReader(path=csv_path)\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "df_pandas_converted = csv_reader.to_pandas()\n",
        "print(\"Pandas DataFrame (first 3 rows):\")\n",
        "print(df_pandas_converted.head(3))\n",
        "\n",
        "# Convert to Polars DataFrame\n",
        "df_polars = csv_reader.to_polars()\n",
        "print(\"\\nPolars DataFrame (first 3 rows):\")\n",
        "print(df_polars.head(3))\n",
        "\n",
        "# Convert to PyArrow Table\n",
        "arrow_table = csv_reader.to_pyarrow_table()\n",
        "print(\"\\nPyArrow Table (first 3 rows):\")\n",
        "print(arrow_table.slice(0, 3).to_pandas())"
      ],
      "id": "0b4bf74f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Writing to Parquet\n",
        "\n",
        "This example shows how to write a Pandas DataFrame to a Parquet file using `ParquetFileWriter`."
      ],
      "id": "90467ced"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: true\n",
        "\n",
        "parquet_writer = ParquetFileWriter(path=parquet_path)\n",
        "print(\"Writing Pandas DataFrame to Parquet...\")\n",
        "parquet_writer.write(df_pandas_original)\n",
        "print(f\"Parquet file created at: {parquet_path}\")\n",
        "print(f\"Parquet file exists: {os.path.exists(parquet_path)}\")"
      ],
      "id": "7292159d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Reading from and Writing to SQLite\n",
        "\n",
        "This example demonstrates how to write data to a SQLite database using `SQLiteWriter` and then read it back using `SQLiteReader`. It also includes an advanced querying example."
      ],
      "id": "a4df2b9b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: true\n",
        "\n",
        "# Writing to SQLite Database\n",
        "sqlite_writer = SQLiteWriter(\n",
        "    table_name=\"employees\",\n",
        "    path=db_path\n",
        ")\n",
        "print(\"Writing data to SQLite Database...\")\n",
        "sqlite_writer.write(df_pandas_original)\n",
        "print(f\"SQLite database created at: {db_path}\")\n",
        "\n",
        "# Reading from SQLite Database\n",
        "sqlite_reader = SQLiteReader(\n",
        "    table_name=\"employees\",\n",
        "    path=db_path\n",
        ")\n",
        "df_from_sqlite_pandas = sqlite_reader.to_pandas()\n",
        "print(\"\\nData read from SQLite (first 5 rows):\")\n",
        "print(df_from_sqlite_pandas.head())\n",
        "\n",
        "# Advanced Querying: Employees older than 50\n",
        "print(\"\\nQuerying: Employees older than 50\")\n",
        "query = \"SELECT * FROM employees WHERE age > 50\"\n",
        "df_older_employees = sqlite_reader.to_pandas(query=query)\n",
        "print(f\"Number of employees older than 50: {len(df_older_employees)}\")\n",
        "print(df_older_employees)\n",
        "\n",
        "# Advanced Querying: Average salary by city\n",
        "print(\"\\nQuerying: Average salary by city\")\n",
        "query = \"SELECT city, AVG(salary) as avg_salary, COUNT(*) as count FROM employees GROUP BY city ORDER BY avg_salary DESC\"\n",
        "df_salary_by_city = sqlite_reader.to_pandas(query=query)\n",
        "print(\"Average salary by city:\")\n",
        "print(df_salary_by_city)"
      ],
      "id": "b5737208",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleanup\n",
        "\n",
        "After running the examples, you can clean up the temporary files created:\n",
        "\n",
        "#| eval: false\n",
        "#| echo: true\n",
        "\n",
        "import shutil\n",
        "\n",
        "print(\"\\nCleaning up temporary files...\")\n",
        "if os.path.exists(csv_path):\n",
        "    os.remove(csv_path)\n",
        "if os.path.exists(parquet_path):\n",
        "    os.remove(parquet_path)\n",
        "if os.path.exists(db_path):\n",
        "    os.remove(db_path)\n",
        "if os.path.exists(temp_dir):\n",
        "    shutil.rmtree(temp_dir)\n",
        "print(\"Cleanup complete.\")"
      ],
      "id": "2e1b73b9"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/z0043ddz/coding/libs/flowerpower-io/.venv/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}